{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os.path as op\n",
    "# import numpy as np\n",
    "# import pylab as pl\n",
    "# import healpy as hp\n",
    "# import scipy as sp\n",
    "# from fgbuster.algebra import comp_sep,W,W_dB,W_dBdB,_utmv,_mmm,_mmv\n",
    "# from fgbuster.mixingmatrix import MixingMatrix\n",
    "# from fgbuster.observation_helpers import standardize_instrument, get_observation\n",
    "# from fgbuster import CMB, Dust, Synchrotron, MixingMatrix, xForecast\n",
    "# from fgbuster.cosmology import _get_Cl_cmb, _get_Cl_noise\n",
    "\n",
    "# __all__ = [\n",
    "#     'xForecast',\n",
    "# ]\n",
    "\n",
    "\n",
    "# def xForecast(components, instrument, d_fgs, lmin, lmax,Alens=1.0, r=0.001, make_figure=True,**minimize_kwargs):\n",
    "    \n",
    "#     # Preliminaries\n",
    "#     instrument = standardize_instrument(instrument)\n",
    "#     nside = hp.npix2nside(d_fgs.shape[-1])\n",
    "#     n_stokes = d_fgs.shape[1]\n",
    "#     n_freqs = d_fgs.shape[0]\n",
    "#     invN = np.diag(hp.nside2resol(nside, arcmin=True) / (instrument.depth_p))**2\n",
    "#     mask = d_fgs[0, 0, :] != 0.\n",
    "#     fsky = mask.astype(float).sum() / mask.size\n",
    "#     ell = np.arange(lmin, lmax+1)\n",
    "    \n",
    "\n",
    "#     ############################################################################\n",
    "#     # 1. Component separation using the noise-free foregrounds templare\n",
    "#     # grab the max-L spectra parameters with the associated error bars\n",
    "   \n",
    "#     A = MixingMatrix(*components)\n",
    "#     A_ev = A.evaluator(instrument.frequency)\n",
    "#     A_dB_ev = A.diff_evaluator(instrument.frequency)\n",
    "\n",
    "#     x0 = np.array([x for c in components for x in c.defaults])\n",
    "#     if n_stokes == 3:  # if T and P were provided, extract P\n",
    "#         d_comp_sep = d_fgs[:, 1:, :]\n",
    "#     else:\n",
    "#         d_comp_sep = d_fgs\n",
    "\n",
    "#     res = comp_sep(A_ev, d_comp_sep.T, invN, A_dB_ev, A.comp_of_dB, x0, **minimize_kwargs)\n",
    "\n",
    "#     res.params = A.params\n",
    "#     res.s = res.s.T\n",
    "#     A_maxL = A_ev(res.x) \n",
    "#     A_dB_maxL = A_dB_ev(res.x)\n",
    "#     A_dBdB_maxL = A.diff_diff_evaluator(instrument.frequency)(res.x)\n",
    "\n",
    "\n",
    "\n",
    "#     ###########################################################################\n",
    "#     #2. Estimate noise after component separation\n",
    "#     ## A^T N_ell^-1 A\n",
    "   \n",
    "#     i_cmb = A.components.index('CMB')\n",
    "#     Cl_noise = _get_Cl_noise(instrument, A_maxL, lmax)[i_cmb, i_cmb, lmin:]\n",
    "\n",
    "#     ############################################################################\n",
    "#     # 3. Compute spectra of the input foregrounds maps\n",
    "#     ### TO DO: which size for Cl_fgs??? N_spec != 1 ? \n",
    "\n",
    "#     if n_stokes == 3:  \n",
    "#         d_spectra = d_fgs\n",
    "#     else:  # Only P is provided, add T for map2alm\n",
    "#         d_spectra = np.zeros((n_freqs, 3, d_fgs.shape[2]), dtype=d_fgs.dtype)\n",
    "#         d_spectra[:, 1:] = d_fgs\n",
    "\n",
    "#     # Compute cross-spectra\n",
    "#     almBs = [hp.map2alm(freq_map, lmax=lmax, iter=10)[2] for freq_map in d_spectra]\n",
    "#     Cl_fgs = np.zeros((n_freqs, n_freqs, lmax+1), dtype=d_fgs.dtype)\n",
    "#     for f1 in range(n_freqs):\n",
    "#         for f2 in range(n_freqs):\n",
    "#             if f1 > f2:\n",
    "#                 Cl_fgs[f1, f2] = Cl_fgs[f2, f1]\n",
    "#             else:\n",
    "#                 Cl_fgs[f1, f2] = hp.alm2cl(almBs[f1], almBs[f2], lmax=lmax)\n",
    "\n",
    "#     Cl_fgs = Cl_fgs[..., lmin:] / fsky\n",
    "\n",
    "#     ############################################################################\n",
    "#     # 4. Estimate the statistical and systematic foregrounds residuals\n",
    "  \n",
    "#     W_maxL = W(A_maxL, invN=invN)[i_cmb, :]\n",
    "#     W_dB_maxL = W_dB(A_maxL, A_dB_maxL, A.comp_of_dB, invN=invN)[:, i_cmb]\n",
    "#     W_dBdB_maxL = W_dBdB(A_maxL, A_dB_maxL, A_dBdB_maxL,A.comp_of_dB, invN=invN)[:, :, i_cmb]\n",
    "\n",
    "   \n",
    "\n",
    "#     V_maxL = np.einsum('ij,ij...->...', res.Sigma, W_dBdB_maxL)\n",
    "#     print(res.Sigma)\n",
    "\n",
    "\n",
    "#     # Check dimentions\n",
    "#     assert ((n_freqs,) == W_maxL.shape == W_dB_maxL.shape[1:]\n",
    "#                        == W_dBdB_maxL.shape[2:] == V_maxL.shape)\n",
    "#     assert (len(res.params) == W_dB_maxL.shape[0] \n",
    "#                             == W_dBdB_maxL.shape[0] == W_dBdB_maxL.shape[1])\n",
    "\n",
    "#     # elementary quantities defined in Stompor, Errard, Poletti (2016)\n",
    "#     Cl_xF = {}\n",
    "#     Cl_xF['yy'] = _utmv(W_maxL, Cl_fgs.T, W_maxL)  # (ell,)\n",
    "#     Cl_xF['YY'] = _mmm(W_dB_maxL, Cl_fgs.T, W_dB_maxL.T)  # (ell, param, param)\n",
    "#     Cl_xF['yz'] = _utmv(W_maxL, Cl_fgs.T, V_maxL )  # (ell,)\n",
    "#     Cl_xF['Yy'] = _mmv(W_dB_maxL, Cl_fgs.T, W_maxL)  # (ell, param)\n",
    "#     Cl_xF['Yz'] = _mmv(W_dB_maxL, Cl_fgs.T, V_maxL)  # (ell, param)\n",
    "\n",
    "  \n",
    "\n",
    "#     # bias and statistical foregrounds residuals\n",
    "#     res.noise = Cl_noise\n",
    "#     res.bias = Cl_xF['yy'] + 2 * Cl_xF['yz']  # S16, Eq 23\n",
    "#     res.stat = np.einsum('ij, lij -> l', res.Sigma, Cl_xF['YY'])  # E11, Eq. 12\n",
    "#     res.var = res.stat**2 + 2 * np.einsum('li, ij, lj -> l', # S16, Eq. 28\n",
    "#                                           Cl_xF['Yy'], res.Sigma, Cl_xF['Yy'])\n",
    "\n",
    "  \n",
    "\n",
    "#     Cl_fid = {}\n",
    "#     Cl_fid['BB'] = _get_Cl_cmb(Alens=Alens, r=r)[2][lmin:lmax+1]\n",
    "#     Cl_fid['BuBu'] = _get_Cl_cmb(Alens=0.0, r=1.0)[2][lmin:lmax+1]\n",
    "#     Cl_fid['BlBl'] = _get_Cl_cmb(Alens=1.0, r=0.0)[2][lmin:lmax+1]\n",
    "\n",
    "#     res.BB = Cl_fid['BB']*1.0\n",
    "#     res.BuBu = Cl_fid['BuBu']*1.0\n",
    "#     res.BlBl = Cl_fid['BlBl']*1.0\n",
    "#     res.ell = ell\n",
    "#     if make_figure:\n",
    "#         fig = pl.figure( figsize=(14,12), facecolor='w', edgecolor='k' )\n",
    "#         ax = pl.gca()\n",
    "#         left, bottom, width, height = [0.2, 0.2, 0.15, 0.2]\n",
    "#         ax0 = fig.add_axes([left, bottom, width, height])\n",
    "#         ax0.set_title(r'$\\ell_{\\min}=$'+str(lmin)+\\\n",
    "#             r'$ \\rightarrow \\ell_{\\max}=$'+str(lmax), fontsize=16)\n",
    "\n",
    "#         ax.loglog(ell, Cl_fid['BB'], color='DarkGray', linestyle='-', label='BB tot', linewidth=2.0)\n",
    "#         ax.loglog(ell, Cl_fid['BuBu']*r , color='DarkGray', linestyle='--', label='primordial BB for r='+str(r), linewidth=2.0)\n",
    "#         ax.loglog(ell, res.stat, 'DarkOrange', label='statistical residuals', linewidth=2.0)\n",
    "#         ax.loglog(ell, res.bias, 'DarkOrange', linestyle='--', label='systematic residuals', linewidth=2.0)\n",
    "#         ax.loglog(ell, res.noise, 'DarkBlue', linestyle='--', label='noise after component separation', linewidth=2.0)\n",
    "#         ax.legend()\n",
    "#         ax.set_xlabel('$\\ell$', fontsize=20)\n",
    "#         ax.set_ylabel('$C_\\ell$ [$\\mu$K-arcmin]', fontsize=20)\n",
    "#         ax.set_xlim(lmin,lmax)\n",
    "\n",
    "\n",
    "# ## 5.1. data \n",
    "#     Cl_obs = Cl_fid['BB'] + Cl_noise\n",
    "#     dof = (2 * ell + 1) * fsky\n",
    "#     YY = Cl_xF['YY']\n",
    "#     tr_SigmaYY = np.einsum('ij, lji -> l', res.Sigma, YY)\n",
    "\n",
    "# ## 5.2. modeling\n",
    "#     def cosmo_likelihood(r_):\n",
    "#         # S16, Appendix C\n",
    "#         Cl_model = Cl_fid['BlBl'] * Alens + Cl_fid['BuBu'] * r_ + Cl_noise\n",
    "#         dof_over_Cl = dof / Cl_model\n",
    "#         ## Eq. C3\n",
    "#         U = np.linalg.inv(res.Sigma_inv + np.dot(YY.T, dof_over_Cl))\n",
    "        \n",
    "#         ## Eq. C9\n",
    "#         first_row = np.sum(dof_over_Cl * (\n",
    "#             Cl_obs * (1 - np.einsum('ij, lji -> l', U, YY) / Cl_model) \n",
    "#             + tr_SigmaYY))\n",
    "#         second_row = - np.einsum(\n",
    "#             'l, m, ij, mjk, kf, lfi',\n",
    "#             dof_over_Cl, dof_over_Cl, U, YY, res.Sigma, YY)\n",
    "#         trCinvC = first_row + second_row\n",
    "       \n",
    "#         ## Eq. C10\n",
    "#         first_row = np.sum(dof_over_Cl * (Cl_xF['yy'] + 2 * Cl_xF['yz']))\n",
    "#         ### Cyclicity + traspose of scalar + grouping terms -> trace becomes\n",
    "#         ### Yy_ell^T U (Yy + 2 Yz)_ell'\n",
    "#         trace = np.einsum('li, ij, mj -> lm',\n",
    "#                           Cl_xF['Yy'], U, Cl_xF['Yy'] + 2 * Cl_xF['Yz'])\n",
    "#         second_row = - _utmv(dof_over_Cl, trace, dof_over_Cl)\n",
    "#         trECinvC = first_row + second_row\n",
    "\n",
    "#         ## Eq. C12\n",
    "#         logdetC = np.sum(dof * np.log(Cl_model)) - np.log(np.linalg.det(U))\n",
    "\n",
    "#         # Cl_hat = Cl_obs + tr_SigmaYY\n",
    "\n",
    "#         ## Bringing things together\n",
    "#         return trCinvC + trECinvC + logdetC\n",
    "\n",
    "\n",
    "#     # Likelihood maximization\n",
    "#     r_grid = np.logspace(-5,0,num=500)\n",
    "#     logL = np.array([cosmo_likelihood(r_loc) for r_loc in r_grid])\n",
    "#     ind_r_min = np.argmin(logL)\n",
    "#     r0 = r_grid[ind_r_min]\n",
    "#     if ind_r_min == 0:\n",
    "#         bound_0 = 0.0\n",
    "#         bound_1 = r_grid[1]\n",
    "#         # pl.figure()\n",
    "#         # pl.semilogx(r_grid, logL, 'r-')\n",
    "#         # pl.show()\n",
    "#     elif ind_r_min == len(r_grid)-1:\n",
    "#         bound_0 = r_grid[-2]\n",
    "#         bound_1 = 1.0\n",
    "#         # pl.figure()\n",
    "#         # pl.semilogx(r_grid, logL, 'r-')\n",
    "#         # pl.show()\n",
    "#     else:\n",
    "#         bound_0 = r_grid[ind_r_min-1]\n",
    "#         bound_1 = r_grid[ind_r_min+1]\n",
    "#     print('bounds on r = ', bound_0, ' / ', bound_1)\n",
    "#     print('starting point = ', r0)\n",
    "#     res_Lr = sp.optimize.minimize(cosmo_likelihood, [r0], bounds=[(bound_0,bound_1)], **minimize_kwargs)\n",
    "#     print ('    ===>> fitted r = ', res_Lr['x'])\n",
    "\n",
    "#     print ('======= ESTIMATION OF SIGMA(R) =======')\n",
    "#     def sigma_r_computation_from_logL(r_loc):\n",
    "#         THRESHOLD = 1.00\n",
    "#         # THRESHOLD = 2.30 when two fitted parameters\n",
    "#         delta = np.abs( cosmo_likelihood(r_loc) - res_Lr['fun'] - THRESHOLD )\n",
    "#         # print r_loc, cosmo_likelihood(r_loc),  res_Lr['fun']\n",
    "#         return delta\n",
    "\n",
    "#     if res_Lr['x'] != 0.0:\n",
    "#         sr_grid = np.logspace(np.log10(res_Lr['x']), 0, num=25)\n",
    "#     else:\n",
    "#         sr_grid = np.logspace(-5,0,num=25)\n",
    "\n",
    "#     slogL = np.array([sigma_r_computation_from_logL(sr_loc) for sr_loc in sr_grid ])\n",
    "#     ind_sr_min = np.argmin(slogL)\n",
    "#     sr0 = sr_grid[ind_sr_min]\n",
    "#     print('ind_sr_min = ', ind_sr_min)\n",
    "#     print('sr_grid[ind_sr_min-1] = ', sr_grid[ind_sr_min-1])\n",
    "#     print('sr_grid[ind_sr_min+1] = ', sr_grid[ind_sr_min+1])\n",
    "#     print('sr_grid = ', sr_grid)\n",
    "#     if ind_sr_min == 0:\n",
    "#         print('case # 1')\n",
    "#         bound_0 = res_Lr['x']\n",
    "#         bound_1 = sr_grid[1]\n",
    "#     elif ind_sr_min == len(sr_grid)-1:\n",
    "#         print('case # 2')\n",
    "#         bound_0 = sr_grid[-2]\n",
    "#         bound_1 = 1.0\n",
    "#     else:\n",
    "#         print('case # 3')\n",
    "#         bound_0 = sr_grid[ind_sr_min-1]\n",
    "#         bound_1 = sr_grid[ind_sr_min+1]\n",
    "#     print('bounds on sigma(r) = ', bound_0, ' / ', bound_1)\n",
    "#     print('starting point = ', sr0)\n",
    "#     res_sr = sp.optimize.minimize(sigma_r_computation_from_logL, sr0,\n",
    "#             bounds=[(bound_0.item(),bound_1.item())],\n",
    "#             # item required for test to pass but reason unclear. sr_grid has\n",
    "#             # extra dimension?\n",
    "#             **minimize_kwargs)\n",
    "#     print ('    ===>> sigma(r) = ', res_sr['x'] -  res_Lr['x'])\n",
    "#     res.cosmo_params = {}\n",
    "#     res.cosmo_params['r'] = (res_Lr['x'], res_sr['x']- res_Lr['x'])\n",
    "\n",
    "#  # 6. Produce figures\n",
    "#     if make_figure:\n",
    "#         print ('======= GRIDDING COSMO LIKELIHOOD =======')\n",
    "#         r_grid = np.logspace(-4,-1,num=500)\n",
    "#         logL = np.array([ cosmo_likelihood(r_loc) for r_loc in r_grid ])\n",
    "#         chi2 = logL - np.min(logL)\n",
    "#         ax0.semilogx( r_grid,  np.exp(-chi2), color='DarkOrange', linestyle='-', linewidth=2.0, alpha=0.8 )\n",
    "#         ax0.axvline(x=r, color='k', linestyle='--')\n",
    "#         ax0.set_ylabel(r'$\\mathcal{L}(r)$', fontsize=20)\n",
    "#         ax0.set_xlabel(r'tensor-to-scalar ratio $r$', fontsize=20)\n",
    "#         pl.show()\n",
    "\n",
    "#     return res\n",
    "\n",
    "# def _get_Cl_noise(instrument, A, lmax):\n",
    "#     try:\n",
    "#         bl = np.array([hp.gauss_beam(np.radians(b/60.), lmax=lmax)\n",
    "#                        for b in instrument.fwhm])\n",
    "#     except AttributeError:\n",
    "#         bl = np.ones((len(instrument.frequency), lmax+1))\n",
    "\n",
    "#     nl = (bl / np.radians(instrument.depth_p/60.)[:, np.newaxis])**2\n",
    "#     AtNA = np.einsum('fi, fl, fj -> lij', A, nl, A)\n",
    "#     inv_AtNA = np.linalg.inv(AtNA)\n",
    "#     return inv_AtNA.swapaxes(-3, -1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nside = 64\n",
    "# model = 'd0s0'\n",
    "\n",
    "\n",
    "# components= [CMB(), Dust(150.), Synchrotron(150.)]\n",
    "\n",
    "# instr = np.load('/Users/alicepirotta/Desktop/APC/MCMC/instrument_LB_IMOv1.npy', allow_pickle=True).item()\n",
    "# instr_ = {}\n",
    "# instr_['frequency'] = np.array([instr[f]['freq'] for f in instr.keys()])\n",
    "# instr_['depth_p'] = np.array([instr[f]['P_sens'] for f in instr.keys()])\n",
    "# instr_['fwhm'] = np.array([instr[f]['beam'] for f in instr.keys()])\n",
    "# instr_['depth_i'] = instr_['depth_p']/np.sqrt(2)\n",
    "# instrument = standardize_instrument(instr_)\n",
    "\n",
    "# d_fgs_N = get_observation(instrument, model, noise=True, nside=nside)\n",
    "# d_fgs = get_observation(instrument, model, noise=False, nside=nside)\n",
    "\n",
    "# #take only the Q and U, not I\n",
    "# freq_maps_N= d_fgs_N[:,1:,:]\n",
    "# freq_maps= d_fgs[:,1:,:]\n",
    "\n",
    "# n_stokes = freq_maps.shape[1]\n",
    "# n_freqs = freq_maps.shape[0]\n",
    "\n",
    "# lmin=2\n",
    "# lmax= 2*nside-1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# xForecast(components, instrument, freq_maps, lmin, lmax,Alens=0.0, r=0.001, make_figure=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pysm3\n",
    "from fgbuster import get_instrument, get_sky, get_observation\n",
    "import healpy as hp\n",
    "import numpy as np\n",
    "from fgbuster import xForecast, CMB, Dust, Synchrotron\n",
    "import os.path as op\n",
    "import numpy as np\n",
    "import pylab as pl\n",
    "import healpy as hp\n",
    "import scipy as sp\n",
    "from fgbuster.algebra import comp_sep,W,W_dB,W_dBdB,_utmv,_mmm,_mmv\n",
    "from fgbuster.mixingmatrix import MixingMatrix\n",
    "from fgbuster.observation_helpers import standardize_instrument, get_observation\n",
    "from fgbuster import CMB, Dust, Synchrotron, MixingMatrix, xForecast\n",
    "from fgbuster.cosmology import _get_Cl_cmb, _get_Cl_noise\n",
    "\n",
    "\n",
    "nside = 64\n",
    "model = 'd0s0'\n",
    "\n",
    "\n",
    "components= [CMB(), Dust(150.), Synchrotron(150.)]\n",
    "\n",
    "instr = np.load('/Users/alicepirotta/Desktop/APC/MCMC/instrument_LB_IMOv1.npy', allow_pickle=True).item()\n",
    "instr_ = {}\n",
    "instr_['frequency'] = np.array([instr[f]['freq'] for f in instr.keys()])\n",
    "instr_['depth_p'] = np.array([instr[f]['P_sens'] for f in instr.keys()])\n",
    "instr_['fwhm'] = np.array([instr[f]['beam'] for f in instr.keys()])\n",
    "instr_['depth_i'] = instr_['depth_p']/np.sqrt(2)\n",
    "instrument = standardize_instrument(instr_)\n",
    "\n",
    "d_fgs_N = get_observation(instrument, model, noise=True, nside=nside)\n",
    "d_fgs = get_observation(instrument, model, noise=False, nside=nside)\n",
    "\n",
    "#take only the Q and U, not I\n",
    "freq_maps_N= d_fgs_N[:,1:,:]\n",
    "freq_maps= d_fgs[:,1:,:]\n",
    "\n",
    "n_stokes = freq_maps.shape[1]\n",
    "n_freqs = freq_maps.shape[0]\n",
    "\n",
    "lmin=2\n",
    "lmax= 2*nside-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create 3% circular sky mask\n",
    "RA = 2*np.pi-70.*np.pi/180\n",
    "DEC = np.pi/2+70.*np.pi/180\n",
    "radius = 34*np.pi/180\n",
    "mask_circular = np.zeros(12*nside**2)\n",
    "for ipix in range(12*nside**2):\n",
    "    theta, phi = hp.pix2ang(nside, ipix)\n",
    "    if (((phi - RA)**2 + (theta - DEC)**2 <= radius**2)):\n",
    "        mask_circular[ipix] = 1.0\n",
    "    if (((phi - RA+2*np.pi)**2 + (theta - DEC)**2 <= radius**2)):\n",
    "        mask_circular[ipix] = 1.0\n",
    "# applying mask to observed frequency maps\n",
    "freq_maps[...,mask_circular==0] = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# define components used in the modeling\n",
    "components = [CMB(), Dust(150.), Synchrotron(150.)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fsky =  0.030192057291666668\n",
      "======= ESTIMATION OF SPECTRAL PARAMETERS =======\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'comp_sep' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# call for xForecast\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39m# with lmin=2, lmax=2*nside-1, and Alens=0.1\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39m# you can try with make_figure=True if you want to output angular power spectra and profile likelihood on r\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m xForecast(components, instrument, freq_maps, lmin, lmax,Alens\u001b[39m=\u001b[39;49m\u001b[39m0.0\u001b[39;49m, r\u001b[39m=\u001b[39;49m\u001b[39m0.001\u001b[39;49m, make_figure\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "File \u001b[0;32m~/fgbuster/fgbuster/cosmology.py:126\u001b[0m, in \u001b[0;36mxForecast\u001b[0;34m(components, instrument, d_fgs, lmin, lmax, Alens, r, make_figure, **minimize_kwargs)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     d_comp_sep \u001b[39m=\u001b[39m d_fgs\n\u001b[0;32m--> 126\u001b[0m res \u001b[39m=\u001b[39m comp_sep(A_ev, d_comp_sep\u001b[39m.\u001b[39mT, invN, A_dB_ev, A\u001b[39m.\u001b[39mcomp_of_dB, x0,\n\u001b[1;32m    127\u001b[0m                \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mminimize_kwargs)\n\u001b[1;32m    129\u001b[0m res\u001b[39m.\u001b[39mparams \u001b[39m=\u001b[39m A\u001b[39m.\u001b[39mparams\n\u001b[1;32m    130\u001b[0m res\u001b[39m.\u001b[39ms \u001b[39m=\u001b[39m res\u001b[39m.\u001b[39ms\u001b[39m.\u001b[39mT\n",
      "\u001b[0;31mNameError\u001b[0m: name 'comp_sep' is not defined"
     ]
    }
   ],
   "source": [
    "# call for xForecast\n",
    "# with lmin=2, lmax=2*nside-1, and Alens=0.1\n",
    "# you can try with make_figure=True if you want to output angular power spectra and profile likelihood on r\n",
    "xForecast(components, instrument, freq_maps, lmin, lmax,Alens=0.0, r=0.001, make_figure=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gain_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
